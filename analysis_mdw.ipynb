{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from collections.abc import Iterable\n",
    "import requests\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import TweetsUtils\n",
    "importlib.reload(TweetsUtils)\n",
    "from TweetsUtils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'en'\n",
    "\n",
    "years = [2018,2019,2021,2022]\n",
    "\n",
    "dates = {2018: ('2018-04-17 00:00:00', '2018-04-22 23:59:59'),\n",
    "         2019: ('2019-04-08 00:00:00', '2019-04-14 23:59:59'), \n",
    "         2021: ('2021-09-04 00:00:00', '2021-09-10 23:59:59'), \n",
    "         2022: ('2022-06-06 00:00:00', '2022-06-12 23:59:59')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tweets(years, lang):\n",
    "    tweets, users, places = [], [], []\n",
    "    for year in years:\n",
    "        tmp_tweets, tmp_users, tmp_places = read_tweets_files(year, lang)\n",
    "        tweets += tmp_tweets\n",
    "        users += tmp_users\n",
    "        places += tmp_places\n",
    "    return tweets, users, places\n",
    "\n",
    "\n",
    "\n",
    "def read_tweets_files(year, lang):\n",
    "    if lang == 'en':\n",
    "        lang = '_en'\n",
    "    else:\n",
    "        lang = ''\n",
    "    \n",
    "    base_path = 'tweets/mdw' + str(year)[-2:] + lang + '_tweets/'\n",
    "    tweets_filename = base_path + 'mdw' + str(year)[-2:] + lang + '_tweets_contents.json'\n",
    "    users_filename = base_path + 'mdw' + str(year)[-2:] + lang + '_tweets_users.json'\n",
    "    places_filename = base_path + 'mdw' + str(year)[-2:] + lang + '_tweets_places.json'\n",
    "    \n",
    "    tmp_tweets = read_file(tweets_filename)\n",
    "    tmp_users = read_file(users_filename)\n",
    "    tmp_places = read_file(places_filename)\n",
    "\n",
    "    for tw in tmp_tweets:\n",
    "        tw['datetime'] = datetime.strptime(tw['datetime'], '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    tmp_tweets = center_week(tmp_tweets, year)\n",
    "    \n",
    "    return tmp_tweets, tmp_users, tmp_places\n",
    "\n",
    "\n",
    "\n",
    "def center_week(tmp_tweets, year):\n",
    "    delta = 60\n",
    "    start_date = datetime.strptime(dates[year][0], '%Y-%m-%d %H:%M:%S') - timedelta(days=delta)\n",
    "    end_date = datetime.strptime(dates[year][1], '%Y-%m-%d %H:%M:%S') + timedelta(days=delta)\n",
    "    return filter_list(tmp_tweets, 'datetime', start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets, users, places = read_tweets(years, lang)\n",
    "\n",
    "print('TOT:', len(tweets), 'tweets')\n",
    "print('TOT:', len(users), 'users')\n",
    "print('TOT:', len(places), 'places')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = read_file('tweets/total_tweets.json')\n",
    "for tw in tweets:\n",
    "    tw['datetime'] = datetime.strptime(tw['datetime'], '%Y-%m-%d %H:%M:%S')\n",
    "tweets = center_week(tweets, 2018) + center_week(tweets, 2019) + center_week(tweets, 2021) + center_week(tweets, 2022)\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignoro i tweet riguardo il salone del mobile di torino\n",
    "tweets = [tw for tw in tweets if not ('torino' in tw['text'].lower() and 'milano' not in tw['text'].lower())]\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tweets = [tw for tw in tweets if is_original(tw)]\n",
    "len(original_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_tweets = read_file('tweets/total_tweets_entities.json')\n",
    "for tw in entities_tweets:\n",
    "    tw['datetime'] = datetime.strptime(tw['datetime'], '%Y-%m-%d %H:%M:%S')\n",
    "entities_tweets = center_week(entities_tweets, 2018) + center_week(entities_tweets, 2019) + center_week(entities_tweets, 2021) + center_week(entities_tweets, 2022)\n",
    "len(entities_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "\n",
    "for lang in ['it', 'en', 'fiera']:\n",
    "    print(lang)\n",
    "    \n",
    "    if lang == 'fiera':\n",
    "        tmp2 = [434000, 386000, 60000, 262000]\n",
    "        tmp = [0] + [np.round(100*(tmp2[i]-tmp2[i-1])/tmp2[i-1], 1) for i in range(1, len(tmp2))]\n",
    "\n",
    "    else:\n",
    "        tmp_tweets, _, _ = read_tweets(years, lang)\n",
    "#         tmp_tweets = [tw for tw in tmp_tweets if is_original(tw)] # only originals\n",
    "        tmp_tweets = [tw for tw in tmp_tweets if not ('torino' in tw['text'].lower() and 'milano' not in tw['text'].lower())]\n",
    "        tmp = [[str(year), len(filter_year(tmp_tweets, year))] for year in years]\n",
    "        tmp = pd.DataFrame(tmp, columns=['year', 'count'])\n",
    "        tmp2 = list(tmp['count'])\n",
    "        tmp['change'] = [0] + [np.round(100*(tmp2[i]-tmp2[i-1])/tmp2[i-1], 1) for i in range(1, len(tmp2))]\n",
    "    \n",
    "    counts[lang] = tmp2\n",
    "    \n",
    "    print(tmp)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (11,4)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "df = pd.DataFrame(counts, index=years)\n",
    "df = pd.DataFrame(df.stack()).reset_index()\n",
    "df.columns = ['year', 'type', 'count']\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "\n",
    "i = 1\n",
    "for _type in ['it', 'fiera']:\n",
    "    plt.subplot(1, 2, i)\n",
    "    tmp = df[df['type']==_type].copy()\n",
    "    col = 'C0' if i == 1 else 'C1'\n",
    "    ax = sns.barplot(data=tmp, x='year', y='count', color=col)\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + ' k'))\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig('test'+_type+'.png', dpi=300, bbox_inches='tight')    \n",
    "    i+=1\n",
    "\n",
    "plt.savefig('test.svg', bbox_inches='tight')\n",
    "plt.show();\n",
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (4,3)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "df = pd.DataFrame(counts, index=years)\n",
    "df = pd.DataFrame(df.stack()).reset_index()\n",
    "df.columns = ['year', 'type', 'count']\n",
    "\n",
    "for _type in ['it', 'en', 'fiera']:\n",
    "    tmp = df[df['type']==_type].copy()\n",
    "    ax = sns.barplot(data=tmp, x='year', y='count', color='green')\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + ' k'))\n",
    "    plt.savefig('test'+_type+'.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show();\n",
    "\n",
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linechart(s, rolling_mean=None, normalize=False):\n",
    "    \n",
    "    if rolling_mean:\n",
    "        s = s.rolling(window=rolling_mean).mean()#.dropna()\n",
    "        \n",
    "    if normalize:\n",
    "        s = (s - s.min()) / (s.max() - s.min())\n",
    "    \n",
    "    plt.plot(s)\n",
    "    \n",
    "    \n",
    "import matplotlib.dates as mdates\n",
    "myFmt = mdates.DateFormatter('%b-%d')\n",
    "\n",
    "\n",
    "for year in [2018,2019,2021,2022]:\n",
    "    year_tweets = filter_year(tweets, year)\n",
    "    s = pd.DataFrame(index=pd.to_datetime([tw['datetime'] for tw in year_tweets]))\n",
    "    s['count'] = [1]*len(s)\n",
    "    s = s.resample('1h').count()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,5))\n",
    "    ax.plot(s)\n",
    "    \n",
    "    delta = 65\n",
    "    start = datetime.strptime(dates[year][0], '%Y-%m-%d %H:%M:%S') - timedelta(days=delta)\n",
    "    end = datetime.strptime(dates[year][1], '%Y-%m-%d %H:%M:%S') + timedelta(days=delta)\n",
    "    plt.xlim(start, end)\n",
    "    \n",
    "    plt.ylim(0, 450)\n",
    "    ax.xaxis.set_major_formatter(myFmt)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h1 = 3\n",
    "h2 = 3\n",
    "freq='3h'\n",
    "\n",
    "t1 = filter_list(tweets, 'datetime', datetime(2018,4,17)-timedelta(h1), datetime(2018,4,23)+timedelta(h2))\n",
    "s = pd.DataFrame(index=[tw['datetime'] for tw in t1])\n",
    "s['count'] = [1]*len(s)\n",
    "s = s.resample(freq).count()\n",
    "s = list(s['count'])\n",
    "plt.plot(s, label='2018')\n",
    "\n",
    "t2 = filter_list(tweets, 'datetime', datetime(2019,4,8)-timedelta(h1), datetime(2019,4,15)+timedelta(h2))\n",
    "s = pd.DataFrame(index=[tw['datetime'] for tw in t2])\n",
    "s['count'] = [1]*len(s)\n",
    "s = s.resample(freq).count()\n",
    "s = list(s['count'])\n",
    "plt.plot(s, label='2019')\n",
    "\n",
    "t3 = filter_list(tweets, 'datetime', datetime(2021,9,4)-timedelta(h1), datetime(2021,9,11)+timedelta(h2))\n",
    "s = pd.DataFrame(index=[tw['datetime'] for tw in t3])\n",
    "s['count'] = [1]*len(s)\n",
    "s = s.resample(freq).count()\n",
    "s = list(s['count'])\n",
    "plt.plot(s, label='2021')\n",
    "\n",
    "t4 = filter_list(tweets, 'datetime', datetime(2022,6,6)-timedelta(h1), datetime(2022,6,13)+timedelta(h2))\n",
    "s = pd.DataFrame(index=[tw['datetime'] for tw in t4])\n",
    "s['count'] = [1]*len(s)\n",
    "s = s.resample(freq).count()\n",
    "s = list(s['count'])\n",
    "plt.plot(s, label='2022')\n",
    "\n",
    "\n",
    "_start = 24/int(freq[0]) * 3\n",
    "_end = 24/int(freq[0]) * 10\n",
    "_max = 1100\n",
    "plt.plot([_start,_start], [0,_max], '--', color='black')\n",
    "plt.plot([_end,_end], [0,_max], '--', color='black')\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,5)\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('events_series.svg', bbox_inches='tight')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_retweets(tweets_list, topn):\n",
    "    x = select_fields(tweets_list, ['referenced_tweets'], as_list=True)\n",
    "    x = [e[0] for e in x if e != []]\n",
    "    ids = [element['id'] for row in x for element in row]\n",
    "    x = pd.value_counts(ids).head(topn)\n",
    "    count = list(x)\n",
    "    texts = []\n",
    "    for _id in x.index:\n",
    "        t = select_fields(filter_list(tweets, 'id', _id), ['text'], as_list=True)[0]\n",
    "        t = t.replace('\\n', '. ').replace('..', '.').replace('. . ', '. ').replace(' . ', '. ')\n",
    "        texts.append(t)\n",
    "    return count, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dei tweet prima e dopo la MDW\n",
    "year = 2022\n",
    "\n",
    "start_date = datetime.strptime(dates[year][0], '%Y-%m-%d %H:%M:%S') - timedelta(days=60)\n",
    "end_date = datetime.strptime(dates[year][0], '%Y-%m-%d %H:%M:%S') \n",
    "tmp = filter_list(tweets, 'datetime', start_date, end_date)\n",
    "c1, t1 = top_retweets(tmp, 3)\n",
    "\n",
    "start_date = datetime.strptime(dates[year][1], '%Y-%m-%d %H:%M:%S')\n",
    "end_date = datetime.strptime(dates[year][1], '%Y-%m-%d %H:%M:%S') + timedelta(days=61)\n",
    "tmp = filter_list(tweets, 'datetime', start_date, end_date)\n",
    "c2, t2 = top_retweets(tmp, 3)\n",
    "\n",
    "\n",
    "for i,t in enumerate(t1):\n",
    "    print(c1[i], '|', t, '\\n')\n",
    "print('---\\n')\n",
    "for i,t in enumerate(t2):\n",
    "    print(c2[i], '|', t, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top retweets globali\n",
    "for year in years:\n",
    "    tmp = filter_year(tweets, year)\n",
    "    c1, t1 = top_retweets(tmp, 3)\n",
    "\n",
    "    for i,t in enumerate(t1):\n",
    "        print(c1[i], '|', t, '\\n')\n",
    "    print('---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = select_fields(tweets, ['author_id'], as_list=True, unique=True)\n",
    "x = filter_list(users, 'id', ids, multiple=True)\n",
    "x = select_fields(x, ['id', 'name', 'followers_count', 'location'])\n",
    "x = pd.DataFrame(x, columns=['id', 'name', 'followers_count', 'location'])\n",
    "x = x.drop_duplicates('id')\n",
    "x = x.sort_values(by='followers_count', ascending=False).head(25)\n",
    "x['location'] = x['location'].apply(lambda x: x['name'] if type(x) == dict else x)\n",
    "x = x.fillna('')\n",
    "x['avg_valence'] = x['id'].apply(lambda x: \n",
    "                                 np.nanmean(select_fields(filter_list(tweets, 'author_id', x), ['valence'], as_list=True)))\n",
    "x['avg_valence'] = x['avg_valence'].fillna(np.nanmean(x['avg_valence'])).round(2)\n",
    "x['count'] = x['id'].apply(lambda _id: len([tw for tw in tweets if tw['author_id']==_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(x, x=\"followers_count\", y=\"name\", \n",
    "             color=\"count\", \n",
    "             title=\"Influencers\", \n",
    "             hover_data={\"location\": True, \"name\": False}, \n",
    "             color_continuous_scale='blugrn', \n",
    "#              color_continuous_scale='RdYlGn', \n",
    "#              range_color=(-0.7,0.7),\n",
    "             width=800, height=700)\n",
    "# fig.update_layout(yaxis_range=[-1,1])\n",
    "fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super tweeters\n",
    "x = tweets.copy()\n",
    "x = pd.value_counts(select_fields(x, ['author_id'], as_list=True)).head(25)\n",
    "\n",
    "tmp = pd.DataFrame([select_fields(filter_list(users, 'id', i), ['id', 'name', 'username', 'followers_count'])[0] \n",
    "                  for i in list(x.index)])\n",
    "tmp['tweets'] = list(x)\n",
    "\n",
    "fig = px.bar(tmp, x='tweets', y='name', \n",
    "             color='tweets', \n",
    "             title=\"Super tweeters\", \n",
    "             hover_data={\"followers_count\": True, \"name\": False, 'username':True, 'tweets':True}, \n",
    "             color_continuous_scale='blugrn', \n",
    "             width=900, height=700)\n",
    "fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super tweeters\n",
    "for year in [2018,2019,2021,2022]:\n",
    "    filtered_tweets = filter_year(tweets, year)\n",
    "    x = pd.value_counts(select_fields(filtered_tweets, ['author_id'], as_list=True)).head(7)\n",
    "\n",
    "    tmp = pd.DataFrame([select_fields(filter_list(users, 'id', i), ['id', 'name', 'username', 'followers_count'])[0] \n",
    "                      for i in list(x.index)])\n",
    "    tmp['tweets'] = list(x)\n",
    "    \n",
    "    tmp['name'] = tmp['name'].apply(lambda x: x[:20]+'...' if len(x)>20 else x)\n",
    "\n",
    "    fig = px.bar(tmp, x='tweets', y='name', \n",
    "                 color='tweets', \n",
    "                 title=str(year),\n",
    "                 hover_data={\"followers_count\": True, \"name\": False, 'username':True, 'tweets':True}, \n",
    "                 range_color=(0,600),\n",
    "                 color_continuous_scale='blugrn', \n",
    "                 width=650, height=325)\n",
    "    \n",
    "    fig.update_layout(xaxis_range=[0,600])\n",
    "    fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet più retweettati\n",
    "x = select_fields(tweets, ['referenced_tweets'], as_list=True)\n",
    "x = [e[0] for e in x if e != []]\n",
    "ids = [element['id'] for row in x for element in row]\n",
    "x = pd.value_counts(ids).head(7)\n",
    "count = list(x)\n",
    "print('xxxxxxxxxxxxxxxxx',count,'\\n')\n",
    "\n",
    "for _id in x.index:\n",
    "    t = select_fields(filter_list(tweets, 'id', _id), ['text'], as_list=True)[0]\n",
    "    print(t.replace('\\n', '. ').replace('..', '.').replace('. . ', '. ').replace(' . ', '. '))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_useless_words():\n",
    "    ignore = ['milano', 'design', 'week', 'fuori', 'salone', 'mobile', 'mdw', \n",
    "          'milanodesignweek', 'salonedelmobile', 'fuorisalone', \n",
    "          '18', '19', '21', '22', '2018', '2019', '2021', '2022']\n",
    "    return ignore + [i+j for i in ignore for j in ignore]\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    tmp = filter_year(tweets, year)\n",
    "\n",
    "    hashtags = select_fields(tmp, ['hashtags'], as_list=True)\n",
    "\n",
    "    # flatten \n",
    "    hashtags = [item[0] for sublist in hashtags for item in sublist if item != []] \n",
    "\n",
    "    # lower\n",
    "    hashtags = [h.lower().strip() for h in hashtags]\n",
    "\n",
    "    # ignore topic words\n",
    "    useless = get_useless_words()\n",
    "    hashtags = [h.replace('ù', 'u') for h in hashtags if h not in useless]\n",
    "    \n",
    "    # count\n",
    "    hashtags = pd.DataFrame(pd.value_counts(hashtags)).head(7)\n",
    "    hashtags = hashtags.reset_index()\n",
    "    hashtags.columns = ['hashtag', 'count']\n",
    "\n",
    "    h_list = list(hashtags['hashtag'])\n",
    "    hashtags['hashtag'] = [''.ljust(int(1.75*(23-len(x)))) + '#' + x for x in h_list]\n",
    "#     hashtags['hashtag'] = '#' + hashtags['hashtag']\n",
    "\n",
    "    fig = px.bar(hashtags, x=\"count\", y=\"hashtag\", \n",
    "             color=\"count\", \n",
    "             hover_data={\"hashtag\": False},\n",
    "                 color_continuous_scale='blugrn', \n",
    "             width=700, height=300)\n",
    "\n",
    "    fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "    fig.update_layout(xaxis_range=[0,500])\n",
    "    fig.update_coloraxes(showscale=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = select_fields(entities_tweets, ['entities'], as_list=True)\n",
    "entities = [e for e in entities if len(e) > 0]\n",
    "entities = [e for sublist in entities for e in sublist] #flatten\n",
    "\n",
    "df = pd.DataFrame(entities)\n",
    "df['text'] = df['text'].str.title()\n",
    "df['text'] = df['text'].str.replace('#', '')\n",
    "df['text'] = df['text'].str.replace('Via Tortona', 'Tortona')\n",
    "df['text'] = df['text'].str.replace('Italy', 'Italia')\n",
    "df['text'] = df['text'].str.replace('..', '', regex=False)\n",
    "df = df[df['text']!='Milano']\n",
    "df['text'] = [''.ljust(int(1.75*(23-len(x)))) + x for x in list(df['text'])]\n",
    "\n",
    "df['type'] = df['type'].str.replace('LOC', 'Luogo')\n",
    "df['type'] = df['type'].str.replace('ORG', 'Organizzazione')\n",
    "df['type'] = df['type'].str.replace('PER', 'Persona')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _type in ['Luogo', 'Organizzazione', 'Persona']:\n",
    "    tmp = df[df['type']==_type]\n",
    "    d = {e[0]: e[1] for e in tmp.values}\n",
    "    \n",
    "    counts = pd.DataFrame(pd.value_counts(tmp['text'])).reset_index().head(10)\n",
    "    counts.columns = ['entity', 'count']\n",
    "    counts['type'] = counts.apply(lambda x: d[x['entity']], axis=1)\n",
    "\n",
    "    fig = px.bar(counts, x=\"count\", y='entity', \n",
    "             color=\"type\", \n",
    "             color_discrete_map={'Luogo': 'lightgreen', 'Organizzazione': 'orange', 'Persona': 'lightblue'}, \n",
    "             hover_data={\"entity\": False},\n",
    "             width=700, height=350)\n",
    "    fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "    fig.update_layout(barmode='stack', yaxis={'categoryorder':'total descending'})\n",
    "    fig.update_coloraxes(showscale=False)\n",
    "    fig.update_layout(xaxis_range=[0,2100])\n",
    "    fig.update_layout(showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    print(year)\n",
    "    tmp = filter_year(entities_tweets, year)\n",
    "    entities = select_fields(tmp, ['entities'], as_list=True)\n",
    "    entities = [e for e in entities if len(e) > 0]\n",
    "    entities = [e for sublist in entities for e in sublist] #flatten\n",
    "    \n",
    "    df = pd.DataFrame(entities)\n",
    "    df['text'] = df['text'].str.title()\n",
    "    df['text'] = df['text'].str.replace('#', '')\n",
    "    df['text'] = df['text'].str.replace('Italy', 'Italia')\n",
    "    df['text'] = df['text'].str.replace('..', '', regex=False)\n",
    "    df['text'] = df['text'].str.replace('Italy', 'Italia')\n",
    "    df = df[df['text']!='Milano']\n",
    "    df['text'] = [''.ljust(int(1.75*(23-len(x)))) + x for x in list(df['text'])]\n",
    "    df['type'] = df['type'].str.replace('LOC', 'Luogo')\n",
    "    df['type'] = df['type'].str.replace('ORG', 'Organizzazione')\n",
    "    df['type'] = df['type'].str.replace('PER', 'Persona')\n",
    "    \n",
    "    d = {e[0]: e[1] for e in df.values}\n",
    "    counts = pd.DataFrame(pd.value_counts(df['text'])).reset_index().head(10)\n",
    "    counts.columns = ['entity', 'count']\n",
    "    counts['type'] = counts.apply(lambda x: d[x['entity']], axis=1)\n",
    "    \n",
    "    fig = px.bar(counts, x=\"count\", y='entity', \n",
    "             color=\"type\", \n",
    "             color_discrete_map= {'Luogo': 'lightgreen', 'Organizzazione': 'orange', 'Persona': 'lightblue'}, \n",
    "             hover_data={\"entity\": False},\n",
    "             width=700, height=350)\n",
    "    fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "    fig.update_layout(barmode='stack', yaxis={'categoryorder':'total descending'})\n",
    "    fig.update_coloraxes(showscale=False)\n",
    "    fig.update_layout(xaxis_range=[0,1600])\n",
    "    fig.update_layout(showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment & emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from TweetsSentiment import TweetsSentiment\n",
    "# ts = TweetsSentiment()\n",
    "\n",
    "# def change_thresholds(tweets, v_threshold, a_threshold):\n",
    "#     for tw in tweets:\n",
    "#         tw['emotion'] = ts.classify_emotion(tw['valence'], tw['arousal'], v_threshold, a_threshold)\n",
    "#         tw['sentiment'] = ts.classify_sentiment(tw['valence'], v_threshold)\n",
    "        \n",
    "# change_thresholds(tweets, 0.35, 0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = 'sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tmp_tweets in [tweets, original_tweets]:\n",
    "\n",
    "    x = {year: list(pd.value_counts(select_fields(filter_year(tmp_tweets, year), [field], as_list=True))) \n",
    "     for year in years}\n",
    "    x = pd.DataFrame(x, index=['neutral', 'positive','negative']).T\n",
    "    x = x.melt()\n",
    "    x['year'] = years*3\n",
    "    # dfs = []\n",
    "    # for year in years:\n",
    "    #     tmp = x[x['year']==year].copy()\n",
    "    #     tmp['perc_value'] = (tmp['value'] / np.sum(tmp['value']) * 100).round(2)\n",
    "    #     tmp['perc_value'] = (tmp['perc_value']).astype(str)\n",
    "    #     tmp['perc_value'] = tmp['perc_value'] + '%'\n",
    "    #     dfs.append(tmp)\n",
    "    # x = pd.concat(dfs)\n",
    "    # fig = px.bar(x, x=\"year\", y=\"value\", color=\"variable\", hover_data={'year':False}, text='perc_value', \n",
    "    #             color_discrete_map={'neutral':'lightgray', 'positive':'green', 'negative':'red'})\n",
    "    # fig.show()\n",
    "\n",
    "    x = x[x['variable']!='neutral']\n",
    "    dfs = []\n",
    "    for year in years:\n",
    "        tmp = x[x['year']==year].copy()\n",
    "        tmp['perc_value'] = (tmp['value'] / np.sum(tmp['value']) * 100).round(2)\n",
    "        tmp['perc_value'] = (tmp['perc_value']).astype(str)\n",
    "        tmp['perc_value'] = tmp['perc_value'] + '%'\n",
    "        dfs.append(tmp)\n",
    "    x = pd.concat(dfs)\n",
    "    fig = px.bar(x, x=\"year\", y=\"value\", color=\"variable\", hover_data={'year':False}, text='perc_value', \n",
    "                color_discrete_map={'neutral':'lightgray', 'positive':'green', 'negative':'red'})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# piecharts\n",
    "\n",
    "for year in [2018,2019,2021, 2022]:\n",
    "    print(year)\n",
    "    filtered_tweets = filter_year(tweets, year)\n",
    "    \n",
    "    x = select_fields(filtered_tweets, [field], as_list=True)\n",
    "    df = pd.DataFrame(pd.value_counts(x), columns=[field])\n",
    "\n",
    "    color_dict = {'neutral':'lightgray', 'positive':'green', 'negative':'red'}\n",
    "    fig = px.pie(df, values=field, names=df.index, color=df.index, hole=0.5, \n",
    "                        color_discrete_map=color_dict, width=400, height=400)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = filter_year(tweets, 2018)\n",
    "tmp = filter_list(tmp, 'sentiment', 'negative')\n",
    "tmp = select_fields(tmp, ['text'], as_list=True, unique=True)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tweets = tweets.copy()\n",
    "\n",
    "# # filter tweets by year\n",
    "# filtered_tweets = filter_year(filtered_tweets, 2018)\n",
    "\n",
    "# # filter tweets by entity / hashtag / user\n",
    "# filtered_tweets = filter_list(filtered_tweets, 'entities', 'Fondazione Prada')\n",
    "\n",
    "# # filter tweets by keyword in text\n",
    "# words = ['traffic', 'parcheggi']\n",
    "# x = select_fields(tweets, ['text'], as_list=True)\n",
    "# filtered_tweets = [tw for tw in filtered_tweets if count_keywords(tw['text'].lower(), words) > 0]\n",
    "\n",
    "print('number of tweets:', len(filtered_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for field in ['emotion', 'sentiment']:\n",
    "    x = select_fields(filtered_tweets, [field], as_list=True)\n",
    "    df = pd.DataFrame(pd.value_counts(x), columns=[field])\n",
    "\n",
    "    color_dict = {'neutral':'lightgray', 'positive':'green', 'negative':'red'}\n",
    "    fig = px.pie(df, values=field, names=df.index, color=df.index, hole=0.5, title=field+' analysis',  \n",
    "                        color_discrete_map=color_dict, width=500, height=400)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentiment in ['negative', 'positive']:\n",
    "    tmp = filter_list(filtered_tweets, 'sentiment', sentiment)\n",
    "    tmp = select_fields(tmp, ['text'], as_list=True)\n",
    "    print('\\n---', sentiment, '---')\n",
    "    for x in tmp:\n",
    "        print('XXXXX', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(select_fields(filtered_tweets, ['valence', 'arousal', 'text']))\n",
    "df['valence'] = df['valence'].round(3)\n",
    "df['arousal'] = df['arousal'].round(3)\n",
    "df['formatted_text'] = df['text'].str.wrap(50).apply(lambda x: x.replace('\\n', '<br>'))\n",
    "df = df[['formatted_text', 'valence', 'arousal',]]\n",
    "\n",
    "fig = px.scatter(df, x=\"valence\", y=\"arousal\", color='valence', \n",
    "                labels={\n",
    "                    \"valence\": \"Valence\",\n",
    "                    \"arousal\": \"Arousal\",\n",
    "                    \"formatted_text\": \"Text\",\n",
    "                }, \n",
    "                hover_data={'formatted_text': True, 'valence': True, 'arousal': True}, \n",
    "\n",
    "                color_continuous_scale='RdYlGn', \n",
    "                range_color=(-1,1),\n",
    "                width=900, height=700)\n",
    "\n",
    "fig.update_traces(marker={'size': 6}, selector=dict(mode='markers'))\n",
    "\n",
    "fig.update_layout(xaxis_range=[-1,1], \n",
    "                  yaxis_range=[-1,1], \n",
    "                  plot_bgcolor='rgba(128,128,128,0.15)')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, os\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def wordcloud(freq, size=(10,7), save=False):\n",
    "    plt.rcParams[\"figure.figsize\"] = size\n",
    "\n",
    "#     # the regex used to detect words is a combination of normal words, ascii art, and emojis\n",
    "#     normal_word = r\"(?:\\w[\\w']+)\"\n",
    "#     ascii_art = r\"(?:[{punctuation}][{punctuation}]+)\".format(punctuation=string.punctuation)\n",
    "#     emoji = r\"(?:[^\\s])(?<![\\w{ascii_printable}])\".format(ascii_printable=string.printable)\n",
    "#     regexp = r\"{normal_word}|{ascii_art}|{emoji}\".format(normal_word=normal_word, ascii_art=ascii_art, emoji=emoji)\n",
    "\n",
    "#     d = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n",
    "#     font_path = os.path.join(d, 'fonts', 'Symbola', 'Symbola.ttf')\n",
    "#     wc = WordCloud(font_path=font_path, regexp=regexp, background_color=\"white\")\n",
    "    \n",
    "    wc = WordCloud(background_color=\"white\", width=1200, height=800)\n",
    "    wc.generate_from_frequencies(freq)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    if save:\n",
    "        wc.to_file(save+'_wordcloud.png')\n",
    "\n",
    "\n",
    "# for emotion in ['joy', 'anticipation', 'trust', 'surprise', 'sadness', 'fear', 'anger', 'neutral']:\n",
    "#     filtered_tweets = filter_list(tweets, 'emotion', emotion)\n",
    "#     texts = select_fields(filtered_tweets, ['lemmatized_text'], as_list=True)\n",
    "    \n",
    "#     texts = ' '.join(texts).split()\n",
    "\n",
    "#     texts = [word.lower().strip() for word in texts \n",
    "#              if word.lower().strip() not in ignore\n",
    "#             and not word.startswith('#')\n",
    "#             and not word.startswith('@')\n",
    "#             and not word.startswith('.')]\n",
    "    \n",
    "#     if len(texts) > 0:\n",
    "#         print()\n",
    "#         print(emotion)\n",
    "#         wordcloud(pd.value_counts(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in ['negative', 'positive']:\n",
    "    filtered_tweets = filter_list(tweets, 'sentiment', emotion)\n",
    "    texts = select_fields(filtered_tweets, ['preprocessed_text'], as_list=True)\n",
    "    \n",
    "    texts = ' '.join(texts).split()\n",
    "\n",
    "    texts = [word.lower().strip() for word in texts \n",
    "             if not word.startswith('.')\n",
    "#             and not word.startswith('#')\n",
    "#             and not word.startswith('@')\n",
    "            and word.isalpha()]\n",
    "    \n",
    "    texts = [t.replace('cazzo', 'c***o') for t in texts]\n",
    "    \n",
    "    if len(texts) > 0:\n",
    "        print()\n",
    "        print(emotion)\n",
    "        wordcloud(pd.value_counts(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    print()\n",
    "    print(year)\n",
    "    for emotion in ['negative', 'positive']:\n",
    "        tmp_tweets = filter_year(tweets, year)\n",
    "        filtered_tweets = filter_list(tmp_tweets, 'sentiment', emotion)\n",
    "        texts = select_fields(filtered_tweets, ['preprocessed_text'], as_list=True)\n",
    "\n",
    "        texts = ' '.join(texts).split()\n",
    "\n",
    "        texts = [word.lower().strip() for word in texts \n",
    "                 if not word.startswith('.')\n",
    "#                 and not word.startswith('#')\n",
    "#                 and not word.startswith('@')\n",
    "                and word.isalpha()]\n",
    "        \n",
    "        texts = [t.replace('cazzo', 'c***o') for t in texts]\n",
    "\n",
    "        if len(texts) > 0:\n",
    "            print()\n",
    "            print(emotion)\n",
    "            wordcloud(pd.value_counts(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for sent in ['negative', 'positive']:\n",
    "        x = filter_list(tweets, 'sentiment', sent)\n",
    "        x = filter_year(x, year)\n",
    "        x = select_fields(x, ['text'], as_list=True)\n",
    "        x = pd.value_counts(x).head(3)\n",
    "#         x = list(x.index)[:3]\n",
    "        print('\\n---', year, sent)\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter by sentiment & emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = 'sentiment'\n",
    "value = 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tweets = filter_list(tweets, field, value).copy()\n",
    "\n",
    "for tw in filtered_tweets:\n",
    "    user = filter_list(users, 'id', tw['author_id'])[0]\n",
    "    tw['user_name'] = user['name']\n",
    "    tw['followers_count'] = user['followers_count']\n",
    "df = select_fields(filtered_tweets, ['user_name', 'followers_count', 'text', 'valence', 'arousal'])\n",
    "df = pd.DataFrame(df)\n",
    "df = df.sort_values(by='valence').reset_index(drop=True)[['text', 'user_name', 'followers_count', 'valence', 'arousal']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_tweets_with_location(tweets, users, places)\n",
    "df['country'] = df['country'].str.replace('Italia', 'Italy')\n",
    "df.index = df['datetime']\n",
    "\n",
    "print('Geolocalization:', len(df[df['type']=='geolocalization']))\n",
    "print('User location:  ', len(df[df['type']=='user_location']))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(df['country'].value_counts()).head(20)\n",
    "x['count'] = x['country']\n",
    "x['country'] = x.index\n",
    "\n",
    "fig = px.bar(x, x='count', y='country', \n",
    "             color='count', \n",
    "             color_continuous_scale='blugrn', \n",
    "             width=700, height=600)\n",
    "fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(df, lat=\"lat\", lon=\"lon\", hover_name=\"country\", \n",
    "                        color_discrete_sequence=[\"fuchsia\"], zoom=1, height=600)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "\n",
    "fig.update_traces(marker=dict(size=5))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [tw['text'] for tw in tweets]\n",
    "pd.value_counts(tmp).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
